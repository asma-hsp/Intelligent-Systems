{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/home/asma/Documents/Intelligent Systems/Home Works/HW4_Datasets/Q1/Test_Data.csv', header=None)\n",
    "test_labels = pd.read_csv('/home/asma/Documents/Intelligent Systems/Home Works/HW4_Datasets/Q1/Test_Labels.csv', header=None)\n",
    "train_data = pd.read_csv('/home/asma/Documents/Intelligent Systems/Home Works/HW4_Datasets/Q1/Train_Data.csv', header=None)\n",
    "train_labels = pd.read_csv('/home/asma/Documents/Intelligent Systems/Home Works/HW4_Datasets/Q1/Train_Labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardaize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    return (data - data.mean()) / data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = standardize(train_data)\n",
    "test_data = standardize(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmean++ from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means(k,data):\n",
    "    \n",
    "    conv = False\n",
    "    data['labels'] = -1\n",
    "    dis = pd.DataFrame(columns=[0, 1 ,2])\n",
    "    dp = pd.DataFrame()\n",
    "    centeroids = data.sample(n=1).drop('labels', axis =1).reset_index(drop=True)\n",
    "    \n",
    "    for i in range(0, k-1):\n",
    "        cnt = centeroids.loc[i]\n",
    "        dff = data.drop('labels', axis=1)-cnt.values.reshape((1, 13))\n",
    "        dp = pd.concat((dff, dp), axis=1).max(axis=1).reset_index(drop=True)\n",
    "        new = data.sample(n=1, weights = dp**2).drop('labels', axis =1)\n",
    "        centeroids = pd.concat([centeroids, new])\n",
    "        centeroids.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    while (conv == False):    \n",
    "        for i, cnt in centeroids.iterrows():\n",
    "            df = data.drop('labels', axis=1)-cnt.values.reshape((1, 13))\n",
    "            dis[i] = LA.norm(df.values, axis=1)\n",
    "            \n",
    "        data['labels'] = dis.idxmin(axis=1)\n",
    "        updates = data.groupby('labels').mean().reset_index(drop=True)\n",
    "    \n",
    "        if (updates.equals(centeroids)):\n",
    "            conv = True\n",
    "        else:\n",
    "            centeroids = updates\n",
    "        \n",
    "    return data, centeroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Intra_Cluster(cluster):\n",
    "    df = cluster - cluster.mean()\n",
    "    intra_distance = LA.norm(df, axis=1)\n",
    "    return intra_distance.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(data):\n",
    "    gdf= data.groupby('labels').apply(lambda group: Intra_Cluster(group))\n",
    "    return gdf.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterating clustring algorithm 100 time and choosing the one with minimum cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster , center= K_means(3, train_data)\n",
    "\n",
    "for i in range(100):\n",
    "    new, cnt = K_means(3, train_data)\n",
    "    if ( cost_function(new) < cost_function(cluster)):\n",
    "        cluster = new\n",
    "        center = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359.6766542570161"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test , centeroids):\n",
    "    dis = pd.DataFrame(columns=[0, 1 ,2])\n",
    "\n",
    "    for i, cnt in centeroids.iterrows():\n",
    "            df =  test -cnt.values.reshape((1, 13))\n",
    "            dis[i] = LA.norm(df.values, axis=1)\n",
    "    \n",
    "    test['labels'] = dis.idxmin(axis=1)\n",
    "\n",
    "    return test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lables = predict(test_data, center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    14\n",
       "2    10\n",
       "1     9\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13\n",
       "2    10\n",
       "0    10\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_lables.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lables +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0],\n",
       "       [ 1,  9,  0],\n",
       "       [ 0,  4, 10]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_labels[0], predicted_lables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "new_train = train_data.to_numpy()\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "sklearn_labels = kmeans.fit_predict(new_train)\n",
    "kmean_centroid = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-3443adf5b9bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msklearn_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "sklearn_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn_lables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-f3ffd859c544>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn_lables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn_lables' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix(test_labels[0], sklearn_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
